{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "074d5022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC USER\\Documents\\Jo√£o Pedro\\UDEMY\\langchain\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI\n",
    "llm= OpenAI(model=\"gpt-3.5-turbo-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16bba1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nEra uma vez um jovem programador chamado Lucas, que estava sempre em busca de novos desafios e conhecimentos na √°rea de tecnologia. Ele havia ouvido falar sobre aprendizado de m√°quina e ficou extremamente curioso sobre essa t√©cnica que permitia √†s m√°quinas aprenderem por si pr√≥prias.\\n\\nDecidido a se aprofundar no assunto, Lucas se matriculou em um curso de aprendizado de m√°quina e ficou maravilhado com todas as possibilidades que essa t√©cnica oferecia. Ele aprendeu que o aprendizado de m√°quina era uma √°rea da intelig√™ncia artificial que tinha como objetivo ensinar as m√°quinas a aprenderem a partir de dados e experi√™ncias passadas.\\n\\nAo longo do curso, Lucas aprendeu sobre os diferentes tipos de algoritmos utilizados no aprendizado de m√°quina, como os algoritmos de aprendizado supervisionado, n√£o supervisionado e por refor√ßo. Ele tamb√©m aprendeu a utilizar ferramentas e linguagens de programa√ß√£o espec√≠ficas para desenvolver modelos de aprendizado de m√°quina.\\n\\nNo in√≠cio, Lucas teve dificuldades em entender alguns conceitos mais complexos, como regress'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"conte uma hist√≥ria sobre aprendizado de m√°quina\"\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1d61f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Era uma vez um jovem programador chamado Lucas, que estava sempre em busca de novos desafios na √°rea de tecnologia. Um dia, ele ouviu falar sobre aprendizado de m√°quina e ficou fascinado com as possibilidades que essa tecnologia poderia trazer.\n",
      "\n",
      "Lucas decidiu se aprofundar no assunto e come√ßou a pesquisar e estudar sobre aprendizado de m√°quina. Ele descobriu que essa √°rea da computa√ß√£o se baseia em algoritmos e modelos estat√≠sticos que permitem que as m√°quinas aprendam a partir de dados e tomem decis√µes inteligentes.\n",
      "\n",
      "Determinado a se tornar um especialista em aprendizado de m√°quina, Lucas se matriculou em cursos online, participou de workshops e confer√™ncias, e dedicava horas a fio todos os dias para estudar e praticar.\n",
      "\n",
      "Com o tempo, ele come√ßou a aplicar seus conhecimentos em pequenos projetos e a criar modelos de aprendizado de m√°quina que pudessem prever resultados e solucionar problemas espec√≠ficos. Ele ficava fascinado com o poder das m√°quinas em aprender e se adaptar a nov"
     ]
    }
   ],
   "source": [
    "prompt = \"conte uma hist√≥ria sobre aprendizado de m√°quina\"\n",
    "for trecho in llm.stream(prompt):\n",
    "    print(trecho, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c989d47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nMem√≥ria RAM √© a sigla para Random Access Memory, que significa Mem√≥ria de Acesso Aleat√≥rio. √â um tipo de mem√≥ria vol√°til presente nos computadores, respons√°vel por armazenar temporariamente os dados e programas que est√£o sendo utilizados pelo sistema operacional e pelos aplicativos em execu√ß√£o.\\n\\nDisco r√≠gido (ou HD) √© um dispositivo de armazenamento de dados n√£o vol√°til presente nos computadores, respons√°vel por armazenar permanentemente os dados e programas do sistema operacional e dos usu√°rios. √â onde s√£o gravados e lidos os arquivos, documentos, programas e demais informa√ß√µes do computador.\\n\\nProcessador √© o componente respons√°vel por realizar as opera√ß√µes de processamento e controle de dados em um computador. Ele √© o \"c√©rebro\" do computador, respons√°vel por executar as instru√ß√µes e comandos de programas e aplicativos. Quanto maior for a capacidade de processamento do processador, mais r√°pido e eficiente ser√° o desempenho do computador.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perguntas =[\n",
    "    \"o que √© mem√≥ria ram?\"\n",
    "    \"o que √© disco r√≠gido?\"\n",
    "    \"o que √© processador?\"\n",
    "]\n",
    "llm.batch(perguntas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63b8161",
   "metadata": {},
   "source": [
    "### ChatModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dd1ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eda4425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "mensagens = [\n",
    "    SystemMessage(content=\"Voc√™ √© um assistente que responde com ironia\"),\n",
    "    HumanMessage(content=\"Qual o papel da mem√≥ria cache?\")\n",
    "    ]\n",
    "resposta = chat.invoke(mensagens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3005105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ah, a mem√≥ria cache, esse recurso maravilhoso que s√≥ serve para deixar seu computador mais lento, √© claro. Afinal, quem precisa de agilidade e efici√™ncia, n√£o √© mesmo?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b9d9999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 49,\n",
       "  'prompt_tokens': 30,\n",
       "  'total_tokens': 79,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-3.5-turbo-0125',\n",
       " 'system_fingerprint': None,\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82a20ad",
   "metadata": {},
   "source": [
    "### Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d282123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e12d519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "mensagens = [\n",
    "    HumanMessage(content=\"Qual √© o primeiro dia da semana?\"),\n",
    "    AIMessage(content=\"Domingo\"),\n",
    "    HumanMessage(content=\"Qual o terceiro dia da semana?\"),\n",
    "    AIMessage(content=\"Ter√ßa-Feira\"),\n",
    "    HumanMessage(content=\"Qual o √∫ltimo dia da semana?\")\n",
    "]\n",
    "\n",
    "response = chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b44aa11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S√°bado'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6e2ed5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Qual √© o primeiro dia da semana?\\nAI: Domingo\\nHuman: Qual o terceiro dia da semana?\\nAI: Ter√ßa-Feira\\nHuman: Qual o √∫ltimo dia da semana?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOpenAI] [2.38s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"S√°bado.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"S√°bado.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 3,\n",
      "                \"prompt_tokens\": 55,\n",
      "                \"total_tokens\": 58,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-627b47a9-1ac4-46ec-8a32-08b97fd905c3-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 3,\n",
      "      \"prompt_tokens\": 55,\n",
      "      \"total_tokens\": 58,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='S√°bado.', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 55, 'total_tokens': 58, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-627b47a9-1ac4-46ec-8a32-08b97fd905c3-0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "\n",
    "langchain.debug = True\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "750258f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f017b2b",
   "metadata": {},
   "source": [
    "### Cacheamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a517c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4fb5e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "mensagens= [\n",
    "    SystemMessage(content=\"Voc√™ √© um assistente ir√¥nico\"),\n",
    "    HumanMessage(content=\"Qual o quinto dia da semana?\")\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "419bf893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import InMemoryCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6470018f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1.45 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='O quinto dia da semana √© o... quinta-feira! Surpreendente, n√£o √©?', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 27, 'total_tokens': 48, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f52d0acc-6855-4709-82f7-54b57f06375d-0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e470670b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='O quinto dia da semana √© o... quinta-feira! Surpreendente, n√£o √©?', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 27, 'total_tokens': 48, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f52d0acc-6855-4709-82f7-54b57f06375d-0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ad682b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path=\"files/langchain_cache.sqlite\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2661c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 62.5 ms\n",
      "Wall time: 197 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='O quinto dia da semana √©... quinta-feira! Surpreendente, n√£o √© mesmo? üòâ', response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 27, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-bb5dc3cb-aa9a-4db7-8eb9-19ffcfe60edb-0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0a60d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
