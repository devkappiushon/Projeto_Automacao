{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f4382c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.llms import OpenAI\n",
    "\n",
    "llm = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a09bfe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "Responda a seguinte pergunta do usuário\n",
    "{pergunta}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7aef24af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Responda a seguinte pergunta do usuário\n",
      "O que é um SaaS?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template.format(pergunta=\"O que é um SaaS?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30b4d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "Responda a seguinte pergunta do usuário em até {n_palavras} palavras:\n",
    "{pergunta}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8778125b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Responda a seguinte pergunta do usuário em até 15 palavras:\n",
      "O que é um SaaS?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template.format(pergunta=\"O que é um SaaS?\", n_palavras=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21273dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "Responda a seguinte pergunta do usuário em até {n_palavras} palavras:\n",
    "{pergunta}\n",
    "\"\"\", partial_variables={\"n_palavras\": 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dcff7faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Responda a seguinte pergunta do usuário em até 10 palavras:\n",
      "O que é LangChain?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template.format(pergunta=\"O que é LangChain?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ec1d8e",
   "metadata": {},
   "source": [
    "### Utilizando Múltiplos Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60a55b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template_word_count = PromptTemplate.from_template(\"\"\"\n",
    "Responda a pergunta em até {n_palavras} palavras:\n",
    "\"\"\")\n",
    "\n",
    "template_line_count = PromptTemplate.from_template(\"\"\"\n",
    "Responda a pergunta em até {n_linhas} linhas:\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "template_idiom = PromptTemplate.from_template(\"\"\"\n",
    "Retorne a resposta em {idiom}.\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "template_final = (template_word_count + template_line_count + template_idiom +\n",
    "                  \"Responda a pergunta seguindo as instruções {pergunta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "687e883b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['idiom', 'n_linhas', 'n_palavras', 'pergunta'] template='\\nResponda a pergunta em até {n_palavras} palavras:\\n\\nResponda a pergunta em até {n_linhas} linhas:\\n\\n\\nRetorne a resposta em {idiom}.\\n\\nResponda a pergunta seguindo as instruções {pergunta}'\n"
     ]
    }
   ],
   "source": [
    "print(template_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b00e5440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe Sun is the star at the center of our solar system.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_final = template_final.format(n_palavras=15, n_linhas = 1, idiom=\"inglês\", pergunta=\"O que é o Sol?\")\n",
    "llm.invoke(prompt_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "99a5f2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Responda a pergunta em até 15 palavras:\n",
      "\n",
      "Responda a pergunta em até 1 linhas:\n",
      "\n",
      "\n",
      "Retorne a resposta em inglês.\n",
      "\n",
      "Responda a pergunta seguindo as instruções O que é o Sol?\n"
     ]
    }
   ],
   "source": [
    "print(prompt_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6bc849",
   "metadata": {},
   "source": [
    "### Templates para Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad16a94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Essa é a minha dúvida: Quem é você?')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_template(\"Essa é a minha dúvida: {duvida}\")\n",
    "chat_template.format_messages(duvida=\"Quem é você?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c6c7b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Você é um assistente irônico e se chama {nome_assistente}\"),\n",
    "        (\"human\", \"Olá como vai?\"),\n",
    "        (\"ai\", \"Estou bem, como posso lhe ajudar?\"),\n",
    "        (\"human\", \"{pergunta}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6daa51e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['nome_assistente', 'pergunta'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['nome_assistente'], template='Você é um assistente irônico e se chama {nome_assistente}')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Olá como vai?')), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Estou bem, como posso lhe ajudar?')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['pergunta'], template='{pergunta}'))])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "455d46d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Você é um assistente irônico e se chama BotX'),\n",
       " HumanMessage(content='Olá como vai?'),\n",
       " AIMessage(content='Estou bem, como posso lhe ajudar?'),\n",
       " HumanMessage(content='Qual seu nome?')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template.format_messages(nome_assistente=\"BotX\", pergunta=\"Qual seu nome?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "077fde59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Meu nome é BotX. Como posso lhe ajudar hoje?', response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 54, 'total_tokens': 70, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b196ca5a-123e-4802-aa45-08c487c60f59-0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "chat=ChatOpenAI()\n",
    "\n",
    "chat.invoke(chat_template.format_messages(nome_assistente=\"BotX\", pergunta=\"Qual seu nome?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83591622",
   "metadata": {},
   "source": [
    "### Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4fa0861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplos = [\n",
    "    {\"pergunta\": \"Qual é a maior montanha do mundo, o Monte Everest ou o K2?\", \n",
    "     \"resposta\": \n",
    "     \"\"\"São necessárias perguntas de acompanhamento aqui: Sim. \n",
    "Pergunta de acompanhamento: Qual é a altura do Monte Everest? \n",
    "Resposta intermediária: O Monte Everest tem 8.848 metros de altura. \n",
    "Pergunta de acompanhamento: Qual é a altura do K2? \n",
    "Resposta intermediária: O K2 tem 8.611 metros de altura. \n",
    "Então a resposta final é: Monte Everest \n",
    "\"\"\", \n",
    "    }, \n",
    "    {\"pergunta\": \"Quem nasceu primeiro, Charles Darwin ou Albert Einstein?\", \n",
    "     \"resposta\": \n",
    "     \"\"\"São necessárias perguntas de acompanhamento aqui: Sim. \n",
    "Pergunta de acompanhamento: Quando nasceu Charles Darwin? \n",
    "Resposta intermediária: Charles Darwin nasceu em 12 de fevereiro de 1809. \n",
    "Pergunta de acompanhamento: Quando nasceu Albert Einstein? \n",
    "Resposta intermediária: Albert Einstein nasceu em 14 de março de 1879. \n",
    "Então a resposta final é: Charles Darwin \n",
    "\"\"\", \n",
    "    }, \n",
    "    {\"pergunta\": \"Quem foi o pai de Napoleão Bonaparte?\",\n",
    "     \"resposta\": \n",
    "     \"\"\"São necessárias perguntas de acompanhamento aqui: Sim. \n",
    "Pergunta de acompanhamento: Quem foi Napoleão Bonaparte? \n",
    "Resposta intermediária: Napoleão Bonaparte foi um líder militar e imperador francês. \n",
    "Pergunta de acompanhamento: Quem foi o pai de Napoleão Bonaparte? \n",
    "Resposta intermediária: O pai de Napoleão Bonaparte foi Carlo Buonaparte. \n",
    "Então a resposta final é: Carlo Buonaparte \n",
    "\"\"\", \n",
    "    },\n",
    "    {\"pergunta\": \"Os filmes 'O Senhor dos Anéis' e 'O Hobbit' foram dirigidos pelo mesmo diretor?\", \n",
    "     \"resposta\": \n",
    "     \"\"\"São necessárias perguntas de acompanhamento aqui: Sim. \n",
    "Pergunta de acompanhamento: Quem dirigiu 'O Senhor dos Anéis'? \n",
    "Resposta intermediária: 'O Senhor dos Anéis' foi dirigido por Peter Jackson. \n",
    "Pergunta de acompanhamento: Quem dirigiu 'O Hobbit'? \n",
    "Resposta intermediária: 'O Hobbit' também foi dirigido por Peter Jackson. \n",
    "Então a resposta final é: Sim \n",
    "\"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8139f2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pergunta Qual é a maior montanha do mundo, o Monte Everest ou o K2?\\nSão necessárias perguntas de acompanhamento aqui: Sim. \\nPergunta de acompanhamento: Qual é a altura do Monte Everest? \\nResposta intermediária: O Monte Everest tem 8.848 metros de altura. \\nPergunta de acompanhamento: Qual é a altura do K2? \\nResposta intermediária: O K2 tem 8.611 metros de altura. \\nEntão a resposta final é: Monte Everest \\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"pergunta\", \"resposta\"],\n",
    "    template=\"Pergunta {pergunta}\\n{resposta}\"\n",
    ")\n",
    "\n",
    "example_prompt.format(**exemplos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf3d78d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    examples=exemplos,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Pergunta: {input}\",\n",
    "    input_variables=[\"input\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb1f056e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSão necessárias perguntas de acompanhamento aqui: Sim. \\nPergunta de acompanhamento: O que é uma classe? \\nResposta intermediária: Uma classe é um conceito fundamental da programação orientada a objetos que representa um conjunto de objetos com características e comportamentos semelhantes. \\nPergunta de acompanhamento: Quais são os métodos em uma classe? \\nResposta intermediária: Os métodos em uma classe são funções ou procedimentos que podem ser chamados para executar ações ou retornar informações sobre objetos dessa classe. \\nEntão a resposta final é: Os métodos em uma classe podem variar, mas geralmente incluem funções de inicialização, getters e setters para as propriedades da classe, e outros métodos específicos para o comportamento desejado.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(prompt.format(input=\"Quais são os métodos que uma classe recebe?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3c2b9145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSão necessárias perguntas de acompanhamento aqui: Não. \\nResposta final: A herança e a implementação de interfaces permitem que uma classe receba métodos de outras classes ou interfaces, permitindo que ela utilize esses métodos em seu próprio código. A herança ocorre quando uma classe é criada a partir de outra classe, e a classe filha herda todos os métodos e atributos da classe pai. Já a implementação de interfaces ocorre quando uma classe implementa uma interface, que contém métodos que devem ser implementados pela classe. Dessa forma, a classe que implementa a interface também recebe os métodos definidos na interface. '"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(prompt.format(input=\"como Uma classe recebe métodos através da herança de outras classes ou da implementação de interfaces, EXPLIQUE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef98298",
   "metadata": {},
   "source": [
    "### Few Shot Prompting em Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a9877e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "chat=ChatOpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df462235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Qual é a maior montanha do mundo, o Monte Everest ou o K2?'), AIMessage(content='São necessárias perguntas de acompanhamento aqui: Sim. \\nPergunta de acompanhamento: Qual é a altura do Monte Everest? \\nResposta intermediária: O Monte Everest tem 8.848 metros de altura. \\nPergunta de acompanhamento: Qual é a altura do K2? \\nResposta intermediária: O K2 tem 8.611 metros de altura. \\nEntão a resposta final é: Monte Everest \\n')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"human\", \"{pergunta}\"),\n",
    "    (\"ai\", \"{resposta}\")]\n",
    ")\n",
    "\n",
    "print(example_prompt.format_messages(**exemplos[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e09968b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_template = FewShotChatMessagePromptTemplate(\n",
    "    examples=exemplos,\n",
    "    example_prompt=example_prompt\n",
    ")\n",
    "\n",
    "prompt_final = ChatPromptTemplate.from_messages([\n",
    "    few_shot_template,\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "prompt = prompt_final.format_messages(input=\"como Uma classe recebe métodos através da herança de outras classes ou da implementação de interfaces, EXPLIQUE\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "927bbc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Quando uma classe herda de outra classe ou implementa uma interface em programação orientada a objetos, ela pode receber métodos dessas classes ou interfaces.\\n\\nNo caso de herança, uma classe filha pode herdar métodos da classe pai. Isso significa que a classe filha terá acesso aos métodos públicos e protegidos da classe pai, podendo utilizá-los diretamente. Essa herança permite reutilizar código e estabelecer uma relação de especialização entre as classes.\\n\\nJá no caso da implementação de interfaces, uma classe que implementa uma interface deve fornecer a implementação dos métodos definidos nessa interface. Isso garante que a classe terá os métodos especificados pela interface, e permite que objetos dessa classe sejam tratados de forma polimórfica, ou seja, como instâncias da interface.\\n\\nEm resumo, quando uma classe herda de outra classe ou implementa uma interface, ela recebe os métodos dessas classes ou interfaces, podendo utilizá-los conforme necessário em sua própria implementação. Isso contribui para a organização do código, reutilização e extensibilidade do sistema.', response_metadata={'token_usage': {'completion_tokens': 250, 'prompt_tokens': 530, 'total_tokens': 780, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-3588021c-b7a3-485e-a2c8-5c33a1406f40-0')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
